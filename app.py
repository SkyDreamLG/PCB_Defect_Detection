# coding:utf-8
from ultralytics import YOLOv10
import torch
import cv2
import numpy as np
from PIL import Image
import os
from pathlib import Path
import matplotlib.pyplot as plt
import base64
from io import BytesIO, StringIO
from flask import Flask, render_template, request, jsonify, session, send_file
import tempfile
import uuid
from threading import Thread, Lock
import time
import queue
from concurrent.futures import ThreadPoolExecutor, as_completed
import logging
from datetime import datetime, timedelta
import psutil
import gc
import zipfile
import csv
import sqlite3
import json
from datetime import datetime, timezone, timedelta

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# ========== é…ç½®ä¸­æ–‡å­—ä½“ ==========
plt.rcParams['font.sans-serif'] = ['WenQuanYi Micro Hei', 'SimHei', 'DejaVu Sans', 'Arial Unicode MS', 'sans-serif']
plt.rcParams['axes.unicode_minus'] = False

# PCBç¼ºé™·ç±»åˆ«æ˜ å°„
DEFECT_MAP = {
    'missing_hole': 'ç¼ºå¤±å­”',
    'mouse_bite': 'é¼ å’¬ç¼ºé™·',
    'short_circuit': 'çŸ­è·¯'
}

# é¢œè‰²æ˜ å°„
COLOR_MAP = {
    'missing_hole': (255, 0, 0),  # çº¢è‰²
    'mouse_bite': (0, 255, 0),  # ç»¿è‰²
    'short_circuit': (0, 0, 255)  # è“è‰²
}

# ç¼ºé™·æè¿°
DEFECT_DESCRIPTIONS = {
    'missing_hole': 'PCBæ¿ä¸Šç¼ºå¤±çš„é’»å­”',
    'mouse_bite': 'ç±»ä¼¼è€é¼ å’¬è¿‡çš„å¼§å½¢ç¼ºé™·',
    'short_circuit': 'çº¿è·¯ä¹‹é—´çš„å¼‚å¸¸è¿æ¥'
}

# å…¨å±€å˜é‡
processing_status = {}
status_lock = Lock()
detector_instance = None
detector_lock = Lock()
task_manager = None
db_manager = None


# ========== æ•°æ®åº“ç®¡ç†å™¨ ==========
class DatabaseManager:
    """SQLiteæ•°æ®åº“ç®¡ç†å™¨ï¼Œè´Ÿè´£å­˜å‚¨æ£€æµ‹å†å²"""

    def __init__(self, db_path='pcb_defect_history.db'):
        self.db_path = db_path
        self.init_database()

    def init_database(self):
        """åˆå§‹åŒ–æ•°æ®åº“è¡¨"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()

                # åˆ›å»ºæ£€æµ‹è®°å½•è¡¨
                cursor.execute('''
                    CREATE TABLE IF NOT EXISTS detection_records (
                        id INTEGER PRIMARY KEY AUTOINCREMENT,
                        task_id TEXT NOT NULL,
                        filename TEXT NOT NULL,
                        file_path TEXT,
                        detected_file_path TEXT,
                        detection_time TEXT NOT NULL,
                        has_defect BOOLEAN DEFAULT 0,
                        defect_count INTEGER DEFAULT 0,
                        defects_json TEXT,
                        conf_threshold REAL,
                        iou_threshold REAL,
                        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                    )
                ''')

                # åˆ›å»ºç´¢å¼•
                cursor.execute('CREATE INDEX IF NOT EXISTS idx_detection_time ON detection_records(detection_time)')
                cursor.execute('CREATE INDEX IF NOT EXISTS idx_filename ON detection_records(filename)')
                cursor.execute('CREATE INDEX IF NOT EXISTS idx_has_defect ON detection_records(has_defect)')

                conn.commit()
                logger.info("âœ… æ•°æ®åº“åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            logger.error(f"æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥: {e}")

    def save_record(self, record):
        """ä¿å­˜æ£€æµ‹è®°å½•"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()

                # è·å–ä¸œå…«åŒºæ—¶é—´
                tz = timezone(timedelta(hours=8))
                detection_time = datetime.now(tz).strftime('%Y-%m-%d %H:%M:%S')

                cursor.execute('''
                    INSERT INTO detection_records 
                    (task_id, filename, file_path, detected_file_path, detection_time, 
                     has_defect, defect_count, defects_json, conf_threshold, iou_threshold)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                ''', (
                    record['task_id'],
                    record['filename'],
                    record.get('file_path', ''),
                    record.get('detected_file_path', ''),
                    detection_time,
                    record.get('has_defect', False),
                    record.get('defect_count', 0),
                    json.dumps(record.get('defects', []), ensure_ascii=False),
                    record.get('conf_threshold', 0.25),
                    record.get('iou_threshold', 0.45)
                ))

                conn.commit()
                return cursor.lastrowid
        except Exception as e:
            logger.error(f"ä¿å­˜è®°å½•å¤±è´¥: {e}")
            return None

    def query_records(self, start_date=None, end_date=None, has_defect=None, filename=None):
        """æŸ¥è¯¢æ£€æµ‹è®°å½•"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                conn.row_factory = sqlite3.Row
                cursor = conn.cursor()

                query = "SELECT * FROM detection_records WHERE 1=1"
                params = []

                if start_date:
                    query += " AND detection_time >= ?"
                    params.append(start_date)

                if end_date:
                    query += " AND detection_time <= ?"
                    params.append(end_date + " 23:59:59")

                if has_defect is not None:
                    query += " AND has_defect = ?"
                    params.append(1 if has_defect else 0)

                if filename:
                    query += " AND filename LIKE ?"
                    params.append(f"%{filename}%")

                query += " ORDER BY detection_time DESC"

                cursor.execute(query, params)
                records = cursor.fetchall()

                # è½¬æ¢ä¸ºå­—å…¸åˆ—è¡¨
                result = []
                for record in records:
                    record_dict = dict(record)
                    # è§£æç¼ºé™·JSON
                    if record_dict['defects_json']:
                        record_dict['defects'] = json.loads(record_dict['defects_json'])
                    else:
                        record_dict['defects'] = []
                    result.append(record_dict)

                return result
        except Exception as e:
            logger.error(f"æŸ¥è¯¢è®°å½•å¤±è´¥: {e}")
            return []

    def get_record_by_id(self, record_id):
        """æ ¹æ®IDè·å–è®°å½•"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                conn.row_factory = sqlite3.Row
                cursor = conn.cursor()
                cursor.execute("SELECT * FROM detection_records WHERE id = ?", (record_id,))
                record = cursor.fetchone()
                if record:
                    record_dict = dict(record)
                    if record_dict['defects_json']:
                        record_dict['defects'] = json.loads(record_dict['defects_json'])
                    else:
                        record_dict['defects'] = []
                    return record_dict
                return None
        except Exception as e:
            logger.error(f"è·å–è®°å½•å¤±è´¥: {e}")
            return None


class TaskManager:
    """ä»»åŠ¡ç®¡ç†å™¨ï¼Œè´Ÿè´£ç®¡ç†å’Œç›‘æ§æ‰€æœ‰æ£€æµ‹ä»»åŠ¡"""

    def __init__(self, max_workers=2):
        self.tasks = {}
        self.lock = Lock()
        self.executor = ThreadPoolExecutor(max_workers=max_workers)
        self.cleanup_thread = Thread(target=self._cleanup_old_tasks, daemon=True)
        self.cleanup_thread.start()
        logger.info(f"ä»»åŠ¡ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆï¼Œæœ€å¤§å¹¶å‘: {max_workers}")

    def create_task(self, task_id, total_files):
        """åˆ›å»ºæ–°ä»»åŠ¡"""
        with self.lock:
            self.tasks[task_id] = {
                'id': task_id,
                'status': 'processing',
                'total': total_files,
                'completed': 0,
                'progress': 0,
                'results': [None] * total_files,
                'errors': [],
                'created_at': time.time(),
                'last_updated': time.time()
            }
        return self.tasks[task_id]

    def update_task(self, task_id, **kwargs):
        """æ›´æ–°ä»»åŠ¡çŠ¶æ€"""
        with self.lock:
            if task_id in self.tasks:
                self.tasks[task_id].update(kwargs)
                self.tasks[task_id]['last_updated'] = time.time()

                # è®¡ç®—è¿›åº¦
                if 'completed' in kwargs and self.tasks[task_id]['total'] > 0:
                    progress = (kwargs['completed'] / self.tasks[task_id]['total']) * 100
                    self.tasks[task_id]['progress'] = progress

                    # å¦‚æœå®Œæˆæ•°é‡ç­‰äºæ€»æ•°ï¼Œæ ‡è®°ä¸ºå®Œæˆ
                    if kwargs['completed'] >= self.tasks[task_id]['total']:
                        self.tasks[task_id]['status'] = 'completed'
                        self.tasks[task_id]['progress'] = 100

    def get_task(self, task_id):
        """è·å–ä»»åŠ¡ä¿¡æ¯"""
        with self.lock:
            task = self.tasks.get(task_id)
            if task:
                # è¿”å›å‰¯æœ¬ï¼Œé¿å…ä¿®æ”¹
                return task.copy()
            return None

    def _cleanup_old_tasks(self):
        """æ¸…ç†30åˆ†é’Ÿå‰çš„æ—§ä»»åŠ¡"""
        while True:
            time.sleep(300)  # æ¯5åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡
            try:
                current_time = time.time()
                with self.lock:
                    to_delete = []
                    for task_id, task in self.tasks.items():
                        # æ¸…ç†30åˆ†é’Ÿå‰çš„å·²å®Œæˆæˆ–é”™è¯¯ä»»åŠ¡
                        if task['status'] in ['completed', 'error']:
                            if current_time - task['last_updated'] > 1800:  # 30åˆ†é’Ÿ
                                to_delete.append(task_id)

                    for task_id in to_delete:
                        del self.tasks[task_id]

                    if to_delete:
                        logger.info(f"æ¸…ç†äº† {len(to_delete)} ä¸ªæ—§ä»»åŠ¡")
            except Exception as e:
                logger.error(f"æ¸…ç†ä»»åŠ¡æ—¶å‡ºé”™: {e}")


class ModelManager:
    """æ¨¡å‹ç®¡ç†å™¨ï¼Œè´Ÿè´£æ¨¡å‹çš„åŠ è½½å’Œæ¨ç†"""

    def __init__(self, model_path='PCB_Defect_Detection/yolov10s_ep300_bs24/weights/best.pt'):
        self.model_path = model_path
        self.model = None
        self.device = self._get_device()
        self.lock = Lock()
        self.load_model()

    def _get_device(self):
        """è·å–å¯ç”¨è®¾å¤‡"""
        if torch.cuda.is_available():
            device = 0
            logger.info(f"ä½¿ç”¨GPU: {torch.cuda.get_device_name(0)}")
        else:
            device = 'cpu'
            logger.info("ä½¿ç”¨CPU")
        return device

    def load_model(self):
        """åŠ è½½æ¨¡å‹ï¼ˆå…¼å®¹PyTorch 2.6+ï¼‰"""
        try:
            with self.lock:
                if self.model is None:
                    logger.info(f"åŠ è½½æ¨¡å‹: {self.model_path}")

                    # æ£€æŸ¥PyTorchç‰ˆæœ¬
                    torch_version = torch.__version__
                    logger.info(f"PyTorchç‰ˆæœ¬: {torch_version}")

                    # è·å–ä¸»ç‰ˆæœ¬å·
                    major_version = int(torch_version.split('.')[0])
                    minor_version = int(torch_version.split('.')[1])

                    # å¯¹äºPyTorch 2.6+ï¼Œéœ€è¦ç‰¹æ®Šå¤„ç†
                    if major_version >= 2 and minor_version >= 6:
                        logger.info("æ£€æµ‹åˆ°PyTorch 2.6+ï¼Œä½¿ç”¨å…¼å®¹æ¨¡å¼åŠ è½½")

                        # æ–¹æ³•1ï¼šä½¿ç”¨ç¯å¢ƒå˜é‡ï¼ˆæœ€ç®€å•ï¼‰
                        os.environ['TORCH_FORCE_WEIGHTS_ONLY_LOAD'] = '0'

                        try:
                            # æ–¹æ³•2ï¼šä½¿ç”¨safe_globalsä¸Šä¸‹æ–‡ç®¡ç†å™¨
                            import ultralytics.nn.tasks

                            # æ·»åŠ å®‰å…¨å…¨å±€ç±»
                            torch.serialization.add_safe_globals([ultralytics.nn.tasks.YOLOv10DetectionModel])

                            # åŠ è½½æ¨¡å‹
                            self.model = YOLOv10(self.model_path)

                        except Exception as e:
                            logger.warning(f"å®‰å…¨åŠ è½½å¤±è´¥ï¼Œå°è¯•å¤‡ç”¨æ–¹æ³•: {e}")

                            # æ–¹æ³•3ï¼šçŒ´å­è¡¥ä¸torch.load
                            import warnings
                            warnings.filterwarnings("ignore", category=UserWarning)

                            # ä¿å­˜åŸå§‹å‡½æ•°
                            original_load = torch.load

                            def patched_load(f, *args, **kwargs):
                                # å¼ºåˆ¶è®¾ç½®weights_only=False
                                kwargs['weights_only'] = False
                                return original_load(f, *args, **kwargs)

                            # åº”ç”¨è¡¥ä¸
                            torch.load = patched_load

                            try:
                                self.model = YOLOv10(self.model_path)
                                logger.info("ä½¿ç”¨çŒ´å­è¡¥ä¸åŠ è½½æˆåŠŸ")
                            except Exception as e2:
                                logger.error(f"çŒ´å­è¡¥ä¸åŠ è½½å¤±è´¥: {e2}")
                                # æ¢å¤åŸå§‹å‡½æ•°
                                torch.load = original_load
                                raise
                            finally:
                                # æ¢å¤åŸå§‹å‡½æ•°
                                torch.load = original_load
                    else:
                        # æ—§ç‰ˆæœ¬PyTorchç›´æ¥åŠ è½½
                        self.model = YOLOv10(self.model_path)

                    logger.info("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")

        except Exception as e:
            logger.error(f"æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            logger.error("è¯·å°è¯•ä»¥ä¸‹è§£å†³æ–¹æ¡ˆï¼š")
            logger.error("1. å‡çº§ultralyticsåŒ…: pip install -U ultralytics")
            logger.error("2. æˆ–è€…é™çº§PyTorch: pip install torch==2.5.1")
            logger.error("3. æˆ–è€…æ‰‹åŠ¨è®¾ç½®ç¯å¢ƒå˜é‡åè¿è¡Œ: export TORCH_FORCE_WEIGHTS_ONLY_LOAD=0 && python app.py")
            raise

    def predict(self, image, conf_threshold=0.25, iou_threshold=0.45):
        """æ‰§è¡Œé¢„æµ‹"""
        try:
            with self.lock:  # ç¡®ä¿æ¨¡å‹æ¨ç†æ˜¯çº¿ç¨‹å®‰å…¨çš„
                results = self.model(
                    image,
                    conf=conf_threshold,
                    iou=iou_threshold,
                    device=self.device,
                    verbose=False  # å‡å°‘æ—¥å¿—è¾“å‡º
                )
            return results
        except Exception as e:
            logger.error(f"é¢„æµ‹å¤±è´¥: {e}")
            raise

    def draw_detections(self, img, results):
        """ç»˜åˆ¶æ£€æµ‹ç»“æœ"""
        img_with_boxes = img.copy()
        detection_list = []

        if results and len(results) > 0:
            boxes = results[0].boxes
            if boxes is not None and len(boxes) > 0:
                for box in boxes:
                    x1, y1, x2, y2 = box.xyxy[0].cpu().numpy().astype(int)
                    conf = float(box.conf[0].cpu().numpy())
                    cls_id = int(box.cls[0].cpu().numpy())
                    cls_name = results[0].names[cls_id]
                    cls_name_cn = DEFECT_MAP.get(cls_name, cls_name)
                    color = COLOR_MAP.get(cls_name, (255, 255, 255))
                    description = DEFECT_DESCRIPTIONS.get(cls_name, '')

                    # ç»˜åˆ¶è¾¹ç•Œæ¡†
                    cv2.rectangle(img_with_boxes, (x1, y1), (x2, y2), color, 2)

                    # ç»˜åˆ¶æ ‡ç­¾
                    label = f"{cls_name} {conf:.2f}"
                    font_scale = 0.5
                    thickness = 1
                    (text_width, text_height), baseline = cv2.getTextSize(
                        label, cv2.FONT_HERSHEY_SIMPLEX, font_scale, thickness
                    )

                    # æ ‡ç­¾èƒŒæ™¯
                    cv2.rectangle(
                        img_with_boxes,
                        (x1, y1 - text_height - 5),
                        (x1 + text_width + 5, y1),
                        color,
                        -1
                    )

                    # æ ‡ç­¾æ–‡å­—
                    cv2.putText(
                        img_with_boxes,
                        label,
                        (x1 + 3, y1 - 3),
                        cv2.FONT_HERSHEY_SIMPLEX,
                        font_scale,
                        (255, 255, 255),
                        thickness
                    )

                    detection_list.append({
                        'defect_type': cls_name_cn,
                        'defect_type_en': cls_name,
                        'description': description,
                        'confidence': conf,
                        'coordinates': [int(x1), int(y1), int(x2), int(y2)],
                        'width': int(x2 - x1),
                        'height': int(y2 - y1)
                    })

        return img_with_boxes, detection_list


# Flaskåº”ç”¨
app = Flask(__name__)
app.config['SECRET_KEY'] = os.urandom(24)
app.config['MAX_CONTENT_LENGTH'] = 100 * 1024 * 1024  # é™åˆ¶ä¸Šä¼ æ–‡ä»¶å¤§å°ä¸º100MB
app.config['UPLOAD_FOLDER'] = 'uploads'
app.config['DETECTED_FOLDER'] = 'detected'

# åˆ›å»ºä¸Šä¼ ç›®å½•
os.makedirs(app.config['UPLOAD_FOLDER'], exist_ok=True)
os.makedirs(app.config['DETECTED_FOLDER'], exist_ok=True)

# åˆå§‹åŒ–ç®¡ç†å™¨
task_manager = TaskManager(max_workers=2)  # é™åˆ¶å¹¶å‘æ•°ä¸º2
db_manager = DatabaseManager()


# æ¨¡å‹æ‡’åŠ è½½
def get_detector():
    """è·å–æ£€æµ‹å™¨å®ä¾‹ï¼ˆæ‡’åŠ è½½ï¼‰"""
    global detector_instance
    with detector_lock:
        if detector_instance is None:
            model_path = 'PCB_Defect_Detection/yolov10s_ep300_bs24/weights/best.pt'
            if not os.path.exists(model_path):
                # å°è¯•ç›¸å¯¹è·¯å¾„
                model_path = os.path.join(os.path.dirname(__file__),
                                          'PCB_Defect_Detection/yolov10s_ep300_bs24/weights/best.pt')
            detector_instance = ModelManager(model_path)
    return detector_instance


@app.route('/')
def index():
    """ä¸»é¡µé¢"""
    return render_template('index.html')


@app.route('/start_batch_detect', methods=['POST'])
def start_batch_detect():
    """å¯åŠ¨æ‰¹é‡æ£€æµ‹ä»»åŠ¡ï¼ˆå¼‚æ­¥å¤„ç†ï¼‰"""
    try:
        files = request.files.getlist('files')
        conf_threshold = float(request.form.get('conf_threshold', 0.25))
        iou_threshold = float(request.form.get('iou_threshold', 0.45))

        if not files:
            return jsonify({'error': 'è¯·ä¸Šä¼ å›¾ç‰‡æ–‡ä»¶'})

        # è§£é™¤20ä¸ªæ–‡ä»¶çš„é™åˆ¶ï¼Œæ”¹ä¸ºæ›´å®½æ¾çš„é™åˆ¶ï¼ˆä¾‹å¦‚1000ä¸ªæ–‡ä»¶ï¼‰
        if len(files) > 1000:
            return jsonify({'error': 'ä¸ºäº†ç³»ç»Ÿæ€§èƒ½ï¼Œå•æ¬¡æœ€å¤šåªèƒ½ä¸Šä¼ 1000å¼ å›¾ç‰‡'})

        # è¯»å–æ–‡ä»¶å†…å®¹
        file_contents = []
        for file in files:
            file.seek(0)
            content = file.read()
            file_contents.append({
                'filename': file.filename,
                'content': content
            })

        # ç”Ÿæˆä»»åŠ¡ID
        task_id = str(uuid.uuid4())

        # åˆ›å»ºä»»åŠ¡
        task_manager.create_task(task_id, len(file_contents))

        # å¯åŠ¨å¼‚æ­¥å¤„ç†
        thread = Thread(
            target=async_process_batch,
            args=(task_id, file_contents, conf_threshold, iou_threshold)
        )
        thread.daemon = True
        thread.start()

        logger.info(f"ä»»åŠ¡åˆ›å»ºæˆåŠŸ: {task_id}, æ–‡ä»¶æ•°: {len(file_contents)}")

        return jsonify({
            'task_id': task_id,
            'message': 'ä»»åŠ¡å·²åˆ›å»º',
            'total_files': len(file_contents)
        })

    except Exception as e:
        logger.error(f"åˆ›å»ºä»»åŠ¡å¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500


def async_process_batch(task_id, file_contents, conf_threshold, iou_threshold):
    """å¼‚æ­¥æ‰¹é‡å¤„ç†"""
    try:
        detector = get_detector()
        total_files = len(file_contents)

        logger.info(f"å¼€å§‹å¤„ç†ä»»åŠ¡ {task_id}, å…± {total_files} å¼ å›¾ç‰‡")

        # é€ä¸ªå¤„ç†æ–‡ä»¶
        for idx, file_data in enumerate(file_contents):
            try:
                # æ›´æ–°çŠ¶æ€
                task_manager.update_task(task_id, status='processing')

                # å¤„ç†å•å¼ å›¾ç‰‡
                img = Image.open(BytesIO(file_data['content']))

                # è½¬æ¢ä¸ºOpenCVæ ¼å¼
                if img.mode != 'RGB':
                    img = img.convert('RGB')
                img_np = np.array(img)
                img_bgr = cv2.cvtColor(img_np, cv2.COLOR_RGB2BGR)

                # é¢„æµ‹
                results = detector.predict(
                    img_bgr,
                    conf_threshold=conf_threshold,
                    iou_threshold=iou_threshold
                )

                # ç»˜åˆ¶æ£€æµ‹ç»“æœ
                img_with_boxes, detections = detector.draw_detections(img_bgr, results)

                # ä¿å­˜åŸå§‹å›¾ç‰‡åˆ°æœåŠ¡å™¨
                timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                safe_filename = f"{timestamp}_{uuid.uuid4().hex[:8]}_{file_data['filename']}"

                # ä¿å­˜åŸå§‹å›¾ç‰‡
                original_path = os.path.join(app.config['UPLOAD_FOLDER'], safe_filename)
                cv2.imwrite(original_path, img_bgr)

                # ä¿å­˜æ£€æµ‹å›¾ç‰‡ï¼ˆå¦‚æœæœ‰ç¼ºé™·ï¼‰
                detected_path = None
                if detections:
                    detected_filename = f"detected_{safe_filename}"
                    detected_path = os.path.join(app.config['DETECTED_FOLDER'], detected_filename)
                    cv2.imwrite(detected_path, img_with_boxes)

                # è½¬æ¢ä¸ºbase64ç”¨äºå‰ç«¯æ˜¾ç¤º
                original_pil = Image.fromarray(cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB))
                detected_pil = Image.fromarray(cv2.cvtColor(img_with_boxes, cv2.COLOR_BGR2RGB))

                original_buffer = BytesIO()
                detected_buffer = BytesIO()

                original_pil.save(original_buffer, format='JPEG', quality=85, optimize=True)
                detected_pil.save(detected_buffer, format='JPEG', quality=85, optimize=True)

                result_item = {
                    'filename': file_data['filename'],
                    'original_image': f"data:image/jpeg;base64,{base64.b64encode(original_buffer.getvalue()).decode()}",
                    'detected_image': f"data:image/jpeg;base64,{base64.b64encode(detected_buffer.getvalue()).decode()}",
                    'detections': detections,
                    'status': 'completed',
                    'index': idx,
                    'file_path': original_path,
                    'detected_file_path': detected_path
                }

                # ä¿å­˜åˆ°æ•°æ®åº“
                db_record = {
                    'task_id': task_id,
                    'filename': file_data['filename'],
                    'file_path': original_path,
                    'detected_file_path': detected_path,
                    'has_defect': len(detections) > 0,
                    'defect_count': len(detections),
                    'defects': detections,
                    'conf_threshold': conf_threshold,
                    'iou_threshold': iou_threshold
                }
                db_manager.save_record(db_record)

                # æ›´æ–°ç»“æœ
                with status_lock:
                    task = task_manager.get_task(task_id)
                    if task:
                        task['results'][idx] = result_item
                        completed = task['completed'] + 1
                        task_manager.update_task(task_id, completed=completed)

                logger.info(f"ä»»åŠ¡ {task_id} è¿›åº¦: {idx + 1}/{total_files}")

                # æ‰‹åŠ¨è§¦å‘åƒåœ¾å›æ”¶
                if idx % 5 == 4:
                    gc.collect()

            except Exception as e:
                logger.error(f"å¤„ç†æ–‡ä»¶ {file_data['filename']} å¤±è´¥: {e}")
                error_item = {
                    'filename': file_data['filename'],
                    'original_image': '',
                    'detected_image': '',
                    'detections': [],
                    'error': str(e),
                    'status': 'error',
                    'index': idx
                }

                with status_lock:
                    task = task_manager.get_task(task_id)
                    if task:
                        task['results'][idx] = error_item
                        completed = task['completed'] + 1
                        task_manager.update_task(task_id, completed=completed)

        logger.info(f"ä»»åŠ¡ {task_id} å¤„ç†å®Œæˆ")

    except Exception as e:
        logger.error(f"ä»»åŠ¡ {task_id} å¤„ç†å¤±è´¥: {e}")
        task_manager.update_task(task_id, status='error', error=str(e))


@app.route('/get_detection_result/<task_id>')
def get_detection_result(task_id):
    """è·å–æ£€æµ‹ç»“æœï¼ˆè½»é‡çº§æ¥å£ï¼‰"""
    try:
        task = task_manager.get_task(task_id)

        if not task:
            return jsonify({'status': 'not_found'})

        # åªè¿”å›å¿…è¦çš„å­—æ®µï¼Œå‡å°‘æ•°æ®ä¼ è¾“
        response = {
            'status': task['status'],
            'progress': task.get('progress', 0),
            'results': []
        }

        # åªè¿”å›å·²å®Œæˆçš„ç»“æœ
        for result in task.get('results', []):
            if result and result.get('status') in ['completed', 'error']:
                response['results'].append(result)

        return jsonify(response)

    except Exception as e:
        logger.error(f"è·å–ç»“æœå¤±è´¥: {e}")
        return jsonify({'status': 'error', 'error': str(e)}), 500


@app.route('/download_results', methods=['POST'])
def download_results():
    """ä¸‹è½½æ£€æµ‹ç»“æœï¼ˆåŒ…å«åŸå§‹å›¾ç‰‡ã€æ£€æµ‹å›¾ç‰‡å’ŒCSVæŠ¥å‘Šï¼‰"""
    try:
        data = request.get_json()
        results = data.get('results', [])

        if not results:
            return jsonify({'error': 'æ²¡æœ‰ç»“æœæ•°æ®'}), 400

        # åˆ›å»ºZIPæ–‡ä»¶
        zip_buffer = BytesIO()
        with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zip_file:
            # åˆ›å»ºå­ç›®å½•
            zip_file.writestr('original_images/', '')  # åŸå§‹å›¾ç‰‡ç›®å½•
            zip_file.writestr('detected_images/', '')  # æ£€æµ‹å›¾ç‰‡ç›®å½•

            # å†™å…¥å›¾ç‰‡å’ŒCSVæŠ¥å‘Š
            for result in results:
                filename = result['filename']

                # å¤„ç†åŸå§‹å›¾ç‰‡
                if result['original_image']:
                    # æå–base64æ•°æ®
                    base64_data = result['original_image'].split(',')[1]
                    img_bytes = base64.b64decode(base64_data)
                    zip_file.writestr(f'original_images/{filename}', img_bytes)

                # å¤„ç†æ£€æµ‹å›¾ç‰‡
                if result['detected_image']:
                    # æå–base64æ•°æ®
                    base64_data = result['detected_image'].split(',')[1]
                    img_bytes = base64.b64decode(base64_data)
                    # ä½¿ç”¨ç›¸åŒæ–‡ä»¶åä½†æ·»åŠ _detectedåç¼€
                    detected_filename = f'{os.path.splitext(filename)[0]}_detected{os.path.splitext(filename)[1]}'
                    zip_file.writestr(f'detected_images/{detected_filename}', img_bytes)

            # åˆ›å»ºCSVæŠ¥å‘Š
            csv_buffer = StringIO()
            fieldnames = ['filename', 'defect_type', 'defect_description', 'confidence', 'x1', 'y1', 'x2', 'y2',
                          'width', 'height']
            writer = csv.DictWriter(csv_buffer, fieldnames=fieldnames)
            writer.writeheader()

            for result in results:
                if result['detections']:  # å¦‚æœæœ‰ç¼ºé™·
                    for detection in result['detections']:
                        writer.writerow({
                            'filename': result['filename'],
                            'defect_type': detection['defect_type'],
                            'defect_description': detection['description'],
                            'confidence': detection['confidence'],
                            'x1': detection['coordinates'][0],
                            'y1': detection['coordinates'][1],
                            'x2': detection['coordinates'][2],
                            'y2': detection['coordinates'][3],
                            'width': detection['width'],
                            'height': detection['height']
                        })
                else:  # æ­£å¸¸å›¾ç‰‡
                    writer.writerow({
                        'filename': result['filename'],
                        'defect_type': 'æ­£å¸¸',
                        'defect_description': 'æ— ç¼ºé™·',
                        'confidence': '',
                        'x1': '',
                        'y1': '',
                        'x2': '',
                        'y2': '',
                        'width': '',
                        'height': ''
                    })

            zip_file.writestr('detection_report.csv', csv_buffer.getvalue())

        # è¿”å›ZIPæ–‡ä»¶
        zip_buffer.seek(0)

        return send_file(
            zip_buffer,
            mimetype='application/zip',
            as_attachment=True,
            download_name=f'pcb_defect_results_{datetime.now().strftime("%Y%m%d_%H%M%S")}.zip'
        )

    except Exception as e:
        logger.error(f"ä¸‹è½½ç»“æœå¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500


@app.route('/query_history')
def query_history():
    """æŸ¥è¯¢å†å²è®°å½•"""
    try:
        start_date = request.args.get('start_date')
        end_date = request.args.get('end_date')
        filename = request.args.get('filename')
        has_defect = request.args.get('has_defect')

        # è½¬æ¢has_defectå‚æ•°
        has_defect_bool = None
        if has_defect is not None and has_defect != '':
            has_defect_bool = has_defect == '1'

        records = db_manager.query_records(
            start_date=start_date,
            end_date=end_date,
            filename=filename,
            has_defect=has_defect_bool
        )

        return jsonify({
            'records': records,
            'total': len(records)
        })

    except Exception as e:
        logger.error(f"æŸ¥è¯¢å†å²è®°å½•å¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500


@app.route('/get_history_image/<int:record_id>')
def get_history_image(record_id):
    """è·å–å†å²è®°å½•çš„å›¾ç‰‡"""
    try:
        image_type = request.args.get('type', 'detected')  # 'original' æˆ– 'detected'

        record = db_manager.get_record_by_id(record_id)
        if not record:
            return 'è®°å½•ä¸å­˜åœ¨', 404

        file_path = record['detected_file_path'] if image_type == 'detected' else record['file_path']
        if not file_path or not os.path.exists(file_path):
            return 'å›¾ç‰‡ä¸å­˜åœ¨', 404

        return send_file(file_path, mimetype='image/jpeg')

    except Exception as e:
        logger.error(f"è·å–å†å²å›¾ç‰‡å¤±è´¥: {e}")
        return str(e), 500


@app.route('/download_history')
def download_history():
    """ä¸‹è½½å†å²è®°å½•ï¼ˆæ ¹æ®æŸ¥è¯¢æ¡ä»¶ï¼‰"""
    try:
        start_date = request.args.get('start_date')
        end_date = request.args.get('end_date')
        filename = request.args.get('filename')
        has_defect = request.args.get('has_defect')

        # è½¬æ¢has_defectå‚æ•°
        has_defect_bool = None
        if has_defect is not None and has_defect != '':
            has_defect_bool = has_defect == '1'

        records = db_manager.query_records(
            start_date=start_date,
            end_date=end_date,
            filename=filename,
            has_defect=has_defect_bool
        )

        if not records:
            return jsonify({'error': 'æ²¡æœ‰ç¬¦åˆæ¡ä»¶çš„æ•°æ®'}), 400

        # åˆ›å»ºZIPæ–‡ä»¶
        zip_buffer = BytesIO()
        with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zip_file:
            # åˆ›å»ºCSVæŠ¥å‘Š
            csv_buffer = StringIO()
            fieldnames = ['id', 'filename', 'detection_time', 'has_defect', 'defect_count', 'defects_detail']
            writer = csv.DictWriter(csv_buffer, fieldnames=fieldnames)
            writer.writeheader()

            for record in records:
                # æ·»åŠ å›¾ç‰‡åˆ°ZIP
                if record['file_path'] and os.path.exists(record['file_path']):
                    zip_file.write(record['file_path'], f"original/{record['filename']}")

                if record['detected_file_path'] and os.path.exists(record['detected_file_path']):
                    detected_filename = f"detected_{record['filename']}"
                    zip_file.write(record['detected_file_path'], f"detected/{detected_filename}")

                # å†™å…¥CSVè®°å½•
                defects_detail = ''
                if record.get('defects'):
                    defects_detail = '; '.join(
                        [f"{d['defect_type']}({d['confidence']:.2f})" for d in record['defects']])

                writer.writerow({
                    'id': record['id'],
                    'filename': record['filename'],
                    'detection_time': record['detection_time'],
                    'has_defect': 'æ˜¯' if record['has_defect'] else 'å¦',
                    'defect_count': record['defect_count'],
                    'defects_detail': defects_detail
                })

            zip_file.writestr('history_report.csv', csv_buffer.getvalue())

        zip_buffer.seek(0)

        return send_file(
            zip_buffer,
            mimetype='application/zip',
            as_attachment=True,
            download_name=f'history_{datetime.now().strftime("%Y%m%d_%H%M%S")}.zip'
        )

    except Exception as e:
        logger.error(f"ä¸‹è½½å†å²è®°å½•å¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500


@app.route('/download_history_item/<int:record_id>')
def download_history_item(record_id):
    """ä¸‹è½½å•ä¸ªå†å²è®°å½•"""
    try:
        record = db_manager.get_record_by_id(record_id)
        if not record:
            return jsonify({'error': 'è®°å½•ä¸å­˜åœ¨'}), 404

        # åˆ›å»ºZIPæ–‡ä»¶
        zip_buffer = BytesIO()
        with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zip_file:
            # æ·»åŠ åŸå§‹å›¾ç‰‡
            if record['file_path'] and os.path.exists(record['file_path']):
                zip_file.write(record['file_path'], f"original/{record['filename']}")

            # æ·»åŠ æ£€æµ‹å›¾ç‰‡
            if record['detected_file_path'] and os.path.exists(record['detected_file_path']):
                detected_filename = f"detected_{record['filename']}"
                zip_file.write(record['detected_file_path'], f"detected/{detected_filename}")

            # åˆ›å»ºè¯¦ç»†ä¿¡æ¯æ–‡ä»¶
            info_buffer = StringIO()
            info_buffer.write(f"æ–‡ä»¶å: {record['filename']}\n")
            info_buffer.write(f"æ£€æµ‹æ—¶é—´: {record['detection_time']}\n")
            info_buffer.write(f"æ˜¯å¦æœ‰ç¼ºé™·: {'æ˜¯' if record['has_defect'] else 'å¦'}\n")
            info_buffer.write(f"ç¼ºé™·æ•°é‡: {record['defect_count']}\n\n")

            if record.get('defects'):
                info_buffer.write("ç¼ºé™·è¯¦æƒ…:\n")
                for i, defect in enumerate(record['defects'], 1):
                    info_buffer.write(f"  {i}. ç±»å‹: {defect['defect_type']}\n")
                    info_buffer.write(f"     ç½®ä¿¡åº¦: {defect['confidence']:.2f}\n")
                    info_buffer.write(f"     ä½ç½®: {defect['coordinates']}\n")
                    info_buffer.write(f"     å°ºå¯¸: {defect['width']}x{defect['height']}\n\n")

            zip_file.writestr('details.txt', info_buffer.getvalue())

        zip_buffer.seek(0)

        return send_file(
            zip_buffer,
            mimetype='application/zip',
            as_attachment=True,
            download_name=f'history_item_{record_id}.zip'
        )

    except Exception as e:
        logger.error(f"ä¸‹è½½å†å²è®°å½•é¡¹å¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500


@app.route('/history_detail/<int:record_id>')
def history_detail(record_id):
    """æ˜¾ç¤ºå†å²è®°å½•è¯¦æƒ…é¡µé¢"""
    record = db_manager.get_record_by_id(record_id)
    if not record:
        return 'è®°å½•ä¸å­˜åœ¨', 404

    return render_template('history_detail.html', record=record)


@app.route('/system_status')
def system_status():
    """è·å–ç³»ç»ŸçŠ¶æ€"""
    try:
        # è·å–å†…å­˜ä½¿ç”¨æƒ…å†µ
        process = psutil.Process()
        memory_info = process.memory_info()
        memory_mb = memory_info.rss / 1024 / 1024

        # è·å–å¾…å¤„ç†ä»»åŠ¡æ•°
        pending_tasks = 0
        with status_lock:
            for task_id, task in task_manager.tasks.items():
                if task['status'] == 'processing':
                    pending_tasks += 1

        return jsonify({
            'model_loaded': detector_instance is not None,
            'pending_tasks': pending_tasks,
            'memory_usage': f"{memory_mb:.1f} MB",
            'timestamp': time.time()
        })

    except Exception as e:
        logger.error(f"è·å–ç³»ç»ŸçŠ¶æ€å¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500


# ========== ç»Ÿè®¡é¡µé¢ç›¸å…³è·¯ç”± ==========

@app.route('/stats')
def stats():
    """ç»Ÿè®¡é¡µé¢"""
    return render_template('stats.html')


@app.route('/api/stats/overview')
def get_stats_overview():
    """è·å–ç»Ÿè®¡æ¦‚è§ˆæ•°æ®"""
    try:
        start_date = request.args.get('start_date')
        end_date = request.args.get('end_date')

        # æŸ¥è¯¢è®°å½•ï¼ˆå¸¦æ—¥æœŸç­›é€‰ï¼‰
        records = db_manager.query_records(
            start_date=start_date,
            end_date=end_date
        )

        total_count = len(records)
        defect_count = sum(1 for r in records if r['has_defect'])
        normal_count = total_count - defect_count

        # ç¼ºé™·æ¯”ä¾‹
        defect_ratio = (defect_count / total_count * 100) if total_count > 0 else 0

        return jsonify({
            'total_count': total_count,
            'defect_count': defect_count,
            'normal_count': normal_count,
            'defect_ratio': round(defect_ratio, 2)
        })
    except Exception as e:
        logger.error(f"è·å–ç»Ÿè®¡æ¦‚è§ˆå¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500


@app.route('/api/stats/defect_types')
def get_defect_types_stats():
    """è·å–å„ç±»ç¼ºé™·æ•°é‡ç»Ÿè®¡"""
    try:
        start_date = request.args.get('start_date')
        end_date = request.args.get('end_date')

        records = db_manager.query_records(
            start_date=start_date,
            end_date=end_date,
            has_defect=True  # åªæŸ¥è¯¢æœ‰ç¼ºé™·çš„è®°å½•
        )

        # ç»Ÿè®¡å„ç±»ç¼ºé™·
        defect_counts = {
            'missing_hole': 0,
            'mouse_bite': 0,
            'short_circuit': 0
        }

        defect_names = {
            'missing_hole': 'ç¼ºå¤±å­”',
            'mouse_bite': 'é¼ å’¬ç¼ºé™·',
            'short_circuit': 'çŸ­è·¯'
        }

        for record in records:
            if record.get('defects'):
                for defect in record['defects']:
                    defect_type_en = defect.get('defect_type_en', '')
                    if defect_type_en in defect_counts:
                        defect_counts[defect_type_en] += 1

        # æ ¼å¼åŒ–è¿”å›æ•°æ®
        result = []
        colors = {
            'missing_hole': '#f05454',
            'mouse_bite': '#8ecf8e',
            'short_circuit': '#5f9df3'
        }

        for defect_type_en, count in defect_counts.items():
            result.append({
                'name': defect_names.get(defect_type_en, defect_type_en),
                'name_en': defect_type_en,
                'count': count,
                'color': colors.get(defect_type_en, '#999999')
            })

        return jsonify(result)
    except Exception as e:
        logger.error(f"è·å–ç¼ºé™·ç±»å‹ç»Ÿè®¡å¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500


@app.route('/api/stats/daily')
def get_daily_stats_api():
    """è·å–æ¯æ—¥æ£€æµ‹æ•°é‡ç»Ÿè®¡"""
    try:
        start_date = request.args.get('start_date')
        end_date = request.args.get('end_date')

        if not start_date or not end_date:
            # é»˜è®¤æœ€è¿‘30å¤©
            end_date = datetime.now()
            start_date = end_date - timedelta(days=30)
            start_date = start_date.strftime('%Y-%m-%d')
            end_date = end_date.strftime('%Y-%m-%d')

        daily_stats = get_daily_stats(start_date, end_date)

        return jsonify(daily_stats)
    except Exception as e:
        logger.error(f"è·å–æ¯æ—¥ç»Ÿè®¡å¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500


def get_daily_stats(start_date, end_date):
    """è·å–æ¯æ—¥ç»Ÿè®¡æ•°æ®çš„è¾…åŠ©å‡½æ•°"""
    try:
        with sqlite3.connect(db_manager.db_path) as conn:
            conn.row_factory = sqlite3.Row
            cursor = conn.cursor()

            # æŸ¥è¯¢æ¯æ—¥æ€»æ•°å’Œæœ‰ç¼ºé™·çš„æ•°é‡
            cursor.execute('''
                SELECT 
                    DATE(detection_time) as date,
                    COUNT(*) as total,
                    SUM(CASE WHEN has_defect = 1 THEN 1 ELSE 0 END) as defect_count
                FROM detection_records
                WHERE DATE(detection_time) BETWEEN ? AND ?
                GROUP BY DATE(detection_time)
                ORDER BY date
            ''', (start_date, end_date))

            rows = cursor.fetchall()

            result = []
            for row in rows:
                result.append({
                    'date': row['date'],
                    'total': row['total'],
                    'defect': row['defect_count'] or 0,
                    'normal': row['total'] - (row['defect_count'] or 0)
                })

            return result
    except Exception as e:
        logger.error(f"è·å–æ¯æ—¥ç»Ÿè®¡å¤±è´¥: {e}")
        return []


@app.route('/api/stats/confidence_distribution')
def get_confidence_distribution():
    """è·å–ç¼ºé™·ç½®ä¿¡åº¦åˆ†å¸ƒ"""
    try:
        start_date = request.args.get('start_date')
        end_date = request.args.get('end_date')

        records = db_manager.query_records(
            start_date=start_date,
            end_date=end_date,
            has_defect=True
        )

        confidence_ranges = [
            {'range': '0-0.5', 'min': 0, 'max': 0.5, 'count': 0},
            {'range': '0.5-0.7', 'min': 0.5, 'max': 0.7, 'count': 0},
            {'range': '0.7-0.8', 'min': 0.7, 'max': 0.8, 'count': 0},
            {'range': '0.8-0.9', 'min': 0.8, 'max': 0.9, 'count': 0},
            {'range': '0.9-1.0', 'min': 0.9, 'max': 1.0, 'count': 0}
        ]

        for record in records:
            if record.get('defects'):
                for defect in record['defects']:
                    conf = defect.get('confidence', 0)
                    for range_item in confidence_ranges:
                        if range_item['min'] <= conf < range_item['max']:
                            range_item['count'] += 1
                            break

        return jsonify(confidence_ranges)
    except Exception as e:
        logger.error(f"è·å–ç½®ä¿¡åº¦åˆ†å¸ƒå¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500


@app.route('/api/stats/export')
def export_stats():
    """å¯¼å‡ºç»Ÿè®¡æ•°æ®ä¸ºCSV"""
    try:
        start_date = request.args.get('start_date')
        end_date = request.args.get('end_date')

        # è·å–æ•°æ®
        defect_types = get_defect_types_stats().json
        daily_stats = get_daily_stats(start_date, end_date) if start_date and end_date else []

        # åˆ›å»ºCSV
        output = StringIO()

        # å†™å…¥ç¼ºé™·ç±»å‹ç»Ÿè®¡
        output.write("=== ç¼ºé™·ç±»å‹ç»Ÿè®¡ ===\n")
        writer = csv.writer(output)
        writer.writerow(['ç¼ºé™·ç±»å‹', 'æ•°é‡'])
        for item in defect_types:
            writer.writerow([item['name'], item['count']])

        output.write("\n\n=== æ¯æ—¥æ£€æµ‹ç»Ÿè®¡ ===\n")
        writer = csv.writer(output)
        writer.writerow(['æ—¥æœŸ', 'æ€»æ•°', 'ç¼ºé™·æ•°', 'æ­£å¸¸æ•°'])
        for item in daily_stats:
            writer.writerow([item['date'], item['total'], item['defect'], item['normal']])

        # è¿”å›CSVæ–‡ä»¶
        output.seek(0)
        return send_file(
            BytesIO(output.getvalue().encode('utf-8-sig')),
            mimetype='text/csv',
            as_attachment=True,
            download_name=f'stats_{datetime.now().strftime("%Y%m%d_%H%M%S")}.csv'
        )
    except Exception as e:
        logger.error(f"å¯¼å‡ºç»Ÿè®¡å¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("ğŸš€ PCBç¼ºé™·æ£€æµ‹ç³»ç»Ÿ")
    print("=" * 60)
    print("ğŸŒ è®¿é—®åœ°å€: http://localhost:5000")
    print("ğŸ“ æŒ‰ Ctrl+C é€€å‡º")
    print("=" * 60)

    # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
    model_path = 'PCB_Defect_Detection/yolov10s_ep300_bs24/weights/best.pt'
    if not os.path.exists(model_path):
        alt_path = os.path.join(os.path.dirname(__file__), model_path)
        if os.path.exists(alt_path):
            print(f"âœ… æ‰¾åˆ°æ¨¡å‹æ–‡ä»¶: {alt_path}")
        else:
            print(f"âš ï¸ è­¦å‘Š: æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
            print("   é¦–æ¬¡æ£€æµ‹æ—¶ä¼šè‡ªåŠ¨åŠ è½½æ¨¡å‹")

    # å¯åŠ¨Flaskåº”ç”¨
    app.run(
        host='0.0.0.0',
        port=5000,
        debug=False,
        threaded=True,
        use_reloader=False
    )


if __name__ == '__main__':
    main()